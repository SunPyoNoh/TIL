# R



## 군집분석

### 계층적 군집분석

- 분석자가 군집수를 설정(자르기)

  ```R
  ########### 분석자가 군집수를 설정(자르기) #########
  library(stats)
  library(cluster)
  idist <- dist(iris[1:4])
  hc <- hclust(idist)
  plot(hc, hang = -1)
  rect.hclust(hc, k=4, border = "red")
  
  #군집분석 결과를 대상으로 3개의 군집수르 ㄹ지정
  ghc <- cutree(hc, k=3)
  ghc # 군집을 의미하는 1~3의 숫자로 출력
  
  iris$ghc <- ghc
  table(iris$ghc)
  g1 <- subset(iris, ghc ==1)
  summary(g1[1:4])
  g2 <- subset(iris, ghc ==2)
  summary(g2[1:4])
  g3 <- subset(iris, ghc ==3)
  summary(g3[1:4])
  ```


- 최단연결법(Single Linkage Method)

  > - 군집에 속하는 두 개체(데이터)사이의 최단 거리를 이용
  >
  > - 가장 유사성이 큰 개체들을 군집으로 묶어 나가는 방법
  >
  > - 빠르고, 자료에 대한 단조 변환에 대하여 Tree구조가 불변하기 때문에 순서적 의미를 갖는 자료에 대해서 좋은 경과를 제공함
  > - 최단연결법(Single Linkage Method)은 고립된 군집을 찾는데 유용

```R
a<-c(1, 5)
b<-c(2, 3)
c<-c(5, 7)
d<-c(3, 5)
e<-c(5, 2)
data <- data.frame(a, b, c,d, e)
data
data<-t(data)
data
m1<-hclust(dist(data)^2, method="single")
plot(m1)
```

- 최장연결법(Complete Linkage Method)

  > 군집들의 응집성을 찾는데 유용

```R
#### 최장연결법(Complete Linkage Method)###
군집들의 응집성을 찾는데 유용

m2<-hclust(dist(data)^2, method="complete")
plot(m2)
```

- 와드 연결법(Ward's Method)

  > 새로운 군집으로 인하여 파생되는 ESS(오차 제곱의 합)의 증가량을 두 군집 사이의 거리로 정의하여 가장 유사성이 큰 개체들을 군집으로 묶어가는 방법

```R
m3<-hclust(dist(data)^2, method="ward.D2")
plot(m3)
```

- 평균 연결법(Average Linkage Method)

  > 두 군집 사이의 거리를 각 군집에 속하는 모든 개체들의 평균거리로 정의하여 가장 유사성이 큰 개체들을 군집으로 묶어 가는 방법

```R
m4<-hclust(dist(data)^2, method="average")
plot(m4)
```



### 비계층적 군집 분석

> - 군집의 수가 정해진 상태에서 군집의 중심에서 가장 가까운 개체를 하나씩 포함해 나가는 방법
> - 군집수를 미리 알고 있는 경우 군집 대상의 분포에 따라 군집의 초기값을 설정해 주면, 초기값에 가장 가까운 거리에 있는 대상을 하나씩 더해 가는 방식으로 군집화를 수행
> - 계층적 군집분석을 통해 대략적인 군집의 수를 파악하고 이를 초기 군집 수로 설정하여 비계층적 군집분석을 수행하는 것이 효과적
> - K-means clustering  (stats::kmeans())

```R
###########비계층적 군집 분석 ##############
library(ggplot2)
data("diamonds")
t <- sample(1:nrow(diamonds), 1000)
test <- diamonds[t, ] 
names(test)
str(test)

data <- test[c("price", "carat", "depth", "table")]
head(data)

#계층적 군집분석
result <- hclust(dist(data), method="ave")
result
plot(result, hang = -1)

#3개의 군집수를 적용하여 비계층적 군집분석 수행
result2 <- kmeans(data, 3)
names(result2)
result2$cluster #각 개체가 속하는 군집수 확인

data$cluster <- result2$cluster

#price에 가장 큰 영향을 주는 변수들 확인
cor(data[, -5], method="pearson")
plot(data[, -5]) #변수간의 상관계수 보기

library(corrgram) #상관계수를 생상으로 시각화
corrgram(data[, -5], upper.panel = panel.conf) #상관계수 수치 추가

#비계층분석 결과 price에 가장 영향을 주는 ..군집수 2의 시각화
plot(data$carat, data$price, col=data$cluster)
#중심점 추가
points(result2$centers[, c("carat", "price")], col=c(3,1,2), pch=8, cex=5)
```

```R

############ iris 데이터셋 비계층적 군집 분석 ######
data<-iris
data$Species <- NULL
head(data)
m<-kmeans(data, 3)
m

table(iris$Species, m$cluster)
plot(data[c("Sepal.Length", "Sepal.Width")], main="kmeans", col=m$cluster)

m2<-kmeans(data, 4)
m2

table(iris$Species, m2$cluster)
plot(data[c("Sepal.Length", "Sepal.Width")], main="kmeans", col=m2$cluster)
```





## 연관분석



```R
#arules::read.transactions(), apriori()
install.packages("arules")
library(arules)
tran <- read.transactions("./data/tran.txt", format="basket",sep=",")
#거래 data는 6개
inspect(tran)   #항목(품목) 확인

rule <- apriori(tran, parameter=list(supp=0.3, conf=0.1))  #규칙 16
#맥주를 구매한 사람은 대체로 고기를 사지 않는다
#{라면, 맥주} => {우유}는 향상도가 1.2이므로 두 상품간의 상관성이 높습니다.
rule2 <- apriori(tran, parameter=list(supp=0.1, conf=0.1))  #규칙 32

stran <- read.transactions("./data/demo_single", format="single", cols=c(1,2))
inspect(stran)


stran2 <- read.transactions("./data/single_format.csv", format="single", sep=",", cols=c(1,2), rm.duplicates=T)
stran2      #트랜잭션 248, 항목은 68
summary(stran2)

#규칙 생성 (연관규칙 생성을 위한 평가척도 기본값 supp=0.1, conf=0.8)
astran2 <- apriori(stran2)   # 102 rules

#규칙 확인
inspect(astran2)

#상위 5개만 향상도 기준 내림차순 
inspect(head(sort(astran2, by="lift" ), 5))


##### 연관규칙 생성, 네트워크 형태로 시각화######
data(Adult) 
str(Adult)   #성인 대상 인구 소득에 관한 설문 조사 데이터
# AdultUCI 데이터셋을 트랜잭션 객체로 변환한 데이터셋
# transaction  48,842 , item 는 115 
# 종속변수(Class)에 의해서 연간 개입 수입이 $5만 이상인지를 예측하는 데이터 셋
  
attributes(Adult)  # transaction의 변수와 범주
names(AdultUCI) #15개의 변수(컬럼)명

adult <- as(Adult, "data.frame") 
head(adult)
str(adult)
summary(adult)

ar <- apriori(Adult, parameter=list(supp=0.1, conf=0.8))  #rules는 6,137개

ar2 <- apriori(Adult, parameter=list(supp=0.3, conf=0.95))  #rules는 124개


ar3 <- apriori(Adult, parameter=list(supp=0.35, conf=0.95))  #rules는  67

ar4 <- apriori(Adult, parameter=list(supp=0.4, conf=0.95))  #rules는  36

#상위 6개 규칙
inspect(head(ar4))

#신뢰도 기준 내림차순 정렬 상위 6개
inspect(head(sort(ar4, descreasing=T, by="confidence")))


#향상도 기준 내림차순 정렬 상위 6개
inspect(head(sort(ar4, descreasing=T, by="lift")))


install.packages("arulesViz")
library(arulesViz)

plot(ar3, method="graph", control=list(type="items"))
# 5만 달러 이상의 연봉 수령자와 관련된 연관어 :


plot(ar4, method="graph", control=list(type="items"))
# 5만 달러 이상의 연봉 수령자와 관련된 연관어 :  
#주당근무시간 형태는 full-time
#인종은 백인
#국가는 미국
#자본손실 무
#직업은 자영업
#나이는 중년
#교육수준 ...
#결혼여부 기혼
```



```R
###############Groceries 데이터 셋 연관분석################
data("Groceries")
str(Groceries)
Groceries
#1개월동안 실제 로컬 식품점 매장에서 판매되는 트랜잭션 데이터
#transaction은 9835, item은 169
Groceries_df <- as(Groceries, "data.frame")

rules <- apriori(Groceries, parameter= list(supp=0.001 , conf=0.8))  # rules 410
inspect(rules)
plot(rules, method="grouped")
#빈도수가 가장 높은 상품 순서대로 2개

rules2 <- apriori(Groceries, parameter= list(supp=0.002 , conf=0.8))  # rules 11
inspect(rules2)
plot(rules2, method="grouped")

#빈도수가 가장 높은 상품

규칙이 A상품 ->B상품 형태로 표현 : 왼쪽에 있는 LHS표현, 오른쪽 RHS 표현된다

#최대 길이(LHS와 RHS길이의 합) 3 이하 규칙 생성
rules <- apriori(Groceries, parameter= list(supp=0.001 , conf=0.8 , maxlen=3))  # rules  29
inspect(rules)

rules <- sort(rules, descreasing=T, by="confidence")
inspect(rules)
plot(rules, method="graph", control=list(type="items"))

######특정 상품 서브셋 생성하여 시각화하기######

wmilk <- subset(rules, rhs %in% 'whole milk')
wmilk 
inspect(wmilk)
plot(wmilk, method="graph")
 
aveg <- subset(rules, rhs %in% 'other vegetables')
aveg
inspect(aveg)
plot(aveg, method="graph")
```



```R
################장바구니 연관분석 연습문제 1 ################
연관성 규칙은 상품 호은 서비스 간의 관계를 살펴보고 이로부터 유용한 규칙을 찾아내고자 할 때 이용될 수 있는 기법이다.
데이터들의 빈도수와 동시발생 확률을 이용하여 한 항목들의 그룹과 다른 항목들의 그룹 사이에 강한 연관성이 있음을 밝혀주는 기법이다.

예제 데이터 : B 마트에서 판매된 트랜잭션 데이터 파일
mybasket.csv

변수 : 의류, 냉동식품, 주류, 야채, 제과, 육류, 과자, 생활장식, 우유

분석문제 :
1. 전체 트랜잭션 개수와 상품아이템 유형은 몇개인가?   #transaction:786, item:10

2. 가장  발생빈도가 높은 상품아이템은 무엇인가?  #의류
3. 지지도를 10%로 설정했을 때의 생성되는 규칙의 가짓수는?  #rules: 127
4. 상품 아이템 중에서 가장 발생확률이 높은 아이템과 낮은 아이템은 무엇인가?  #의류, 밀크
5. 가장 발생가능성이 높은 <2개 상품간>의 연관규칙은 무엇인가?  #의류, 제과
6. 가장 발생가능성이 높은 <2개 상품이상에서> <제 3의 상품으로>의 연관규칙은 무엇인가?   #장식, 냉동, 제과

result <- read.transactions("./data/mybasket.csv", format="basket", sep=",")
result
summary(result)
image(result)
as(result, "data.frame")
rules <- apriori(result, parameter=list(supp=0.1, conf=0.1))
inspect(rules)

library(arulesViz)
plot(rules)
plot(rules, method="grouped")  #lhs가로축 조건과 rhs세로축-결과로 구성한 메트릭스 그래프
plot(rules, method="graph", control=list(type="items"))
plot(rules, method="graph", interactive=TRUE , control=list(type="items"))
```


### 트위터 연관어 분석

```R
############## Twitter SNS 연관어 분석 단계 #######################
단계 1] Twitter 로그인  -  https://twitter.com
단계 2] Twitter 앱 만들기  - https://apps.twitter.com/ko
앱 이름, 앱에 대한 설명문 10자 이상 입력, 웹사이트는 운영중인 사이트나 블러그 등 주소 입력
페이지 아래 라이센스 동의
※ Request token URL, Authorize URL, Access token URL  (앱 인증 요청시 필요함)
 
단계 3] Twitter 앱 설정
단계 4] Twitter 앱 키와 접근 토큰 생성

단계 5] Twitter 앱에 관한 사용자의 권한 설정
단계 6] Twitter 앱 토큰 생성
※ Access Token과 Access Token Secret 생성


#######Twitter 앱 인증 
#twitteR 패키지 로딩 ? twitter 인증 관련 함수 제공
#ROAuth  패키지 로딩 ? OAuthFactory 객체 제공
#Base64enc 패키지 로딩 ? enc2utf8()  함수 제공
install.packages("twitteR")
install.packages("ROAuth")
install.packages("base64enc")
library(twitteR)
library(ROAuth)
library(base64enc)


#  Twitter 앱 요청 URL과 API 설정
# [Details] - 3개 url 변수 생성
reqURL <- "https://api.twitter.com/oauth/request_token"
authURL <- "https://api.twitter.com/oauth/authorize"
accessURL <- "https://api.twitter.com/oauth/access_token"

# [Keys and Access Tokens] - 4개 변수 : ##Site에서 받아온다.
apiKey <-  "bINvDLa0dsPbo2la8PiscuUqC" 
apiSecret <- "PKNHc2ls7cnuFPbD0eWYxqXi7QMK2WCucWjYLWShZMQPu77SNS" 
accessToken="632641860-hADhYcejnc2AlMFxFKy7E2BwLmsLsZGiMjaStMcm"
accessTokenSecret="D4m5xjaihndouW4FLg3LxVxBUitRmSjKJBephvmkRL8x5"

# Twitter 앱 인증 요청
twitCred <- OAuthFactory$new(
  consumerKey = apiKey, 
  consumerSecret = apiSecret,
  requestURL = reqURL,
  accessURL = accessURL, 
  authURL = authURL
)


# Twitter 앱 인증 수행
options(RCurlOptions = list(cainfo = system.file("CurlSSL", "cacert.pem", package =  "RCurl")))
twitCred$handshake()

# Twitter 앱 인증을 위한 PIN 받기 => 연결된 웹 화면에서 PIN번호 받아오기
setup_twitter_oauth(apiKey, 
                    apiSecret,
                    accessToken,
                    accessTokenSecret)


# 함수 실행 -> 선택: 1(1: Yes)


##Twitter 앱에 접근하여 데이터 가져오기

# 단계 1 : 검색어 입력과 검색 결과 받기 
keyword <- enc2utf8("빅데이터") # UTF-8 인코딩 방식 지정 - base 패키지 
test <- searchTwitter(keyword, n=300) # twitteR 패키지 제공 
test
class(test) # [1] "list"

# 단계 2 :  list 자료구조를 vector 자료구조로 변경
test_vec <- vector() # vector 객체 생성 
n <- 1: length(test)

for(i in n){
  test_vec[i] <- test[[i]]$getText()
}
test_vec

# data type과 구조보기 
class(test_vec); str(test_vec)

#파일 저장 및 가져오기
write.csv(test_vec, "c:/Rwork/output/test.txt", quote = FALSE, row.names = FALSE)
test_txt <- file("C:/Rwork/output/test.txt")
twitter <- readLines(test_txt)
str(twitter)


## Twitter 검색 데이터 대상 연관어 분석

# 단계 1 : 한글 처리를 위한 패키지 설치
library(rJava) # 아래와 같은 Error 발생 시 Sys.setenv()함수로 java 경로 지정
library(KoNLP) # rJava 라이브러리가 필요함

# 단계 2 :  줄 단위 단어 추출
lword <- Map(extractNoun, twitter) 
length(lword) 
lword <- unique(lword) # 중복제거1(전체 대상)
length(lword) 
lword <- sapply(lword, unique) # 중복제거2(줄 단위 대상) 
length(lword) 
lword # 추출 단어 확인

# 단계 3 :  데이터 전처리
# (1) 길이가 2~4 사이의 단어 필터링 함수 정의
filter1 <- function(x){
  nchar(x) <= 4 && nchar(x) >= 2 && is.hangul(x)
}
# (2) Filter(f,x) -> filter1() 함수를 적용하여 x 벡터 단위 필터링 
filter2 <- function(x){
  Filter(filter1, x)
}

# (3) 줄 단어 대상 필터링
lword <- sapply(lword, filter2)
lword # 추출 단어 확인(길이 1개 단어 삭제됨)

#  트랜잭션 생성 : 연관분석을 위해서 단어를 트랜잭션으로 변환
library(arules) 
wordtran <- as(lword, "transactions") # lword에 중복데이터가 있으면 error발생
wordtran 
inspect(wordtran)  # 트랜잭션 내용 보기

# 단어 간 연관규칙 산출
tranrules <- apriori(wordtran, parameter=list(supp=0.09, conf=0.8))  # 54 rule(s)
inspect(tranrules) # 연관규칙 생성 결과(23개) 보기

# 연관어 시각화 
# (1) 데이터 구조 변경 : 연관규칙 결과 -> 행렬구조 변경(matrix 또는 data.frame) 
rules <- labels(tranrules, ruleSep=" ") # 연관규칙 레이블을 " "으로 구분하여 변경   
rules # 예) 59 {경영,마케팅}   => {자금} -> 59 "{경영,마케팅} {자금}"
class(rules)

rules <- sapply(rules, strsplit, " ",  USE.NAMES=F) 
rules
class(rules) 

# 행 단위로 묶어서 matrix로 반환
rulemat <- do.call("rbind", rules)
rulemat
class(rulemat)

# (2) 연관어 시각화를 위한 igraph 패키지 설치
library(igraph)   

# (3) edgelist보기 - 연관단어를 정점 형태의 목록 제공 
ruleg <- graph.edgelist(rulemat[c(1:54),], directed=F) 

# (4) edgelist 시각화
X11()
plot.igraph(ruleg, vertex.label=V(ruleg)$name,
            vertex.label.cex=1.0, vertex.label.color='black', 
            vertex.size=20, vertex.color='green', vertex.frame.color='blue')

```



## 시계열 분석

> - 시계열 자료 – 시간의 변화에 따라 관측치 또는 통계량의 변화를 기록해 놓은 자료
> - 시계열 자료는 이전에 기록된 자료에 의존적이다.
> - 시계열 자료를 대상으로 분석을 수행하기 위해서는 기존에 관측된 자료들을 분석하여 시계열 모형을 추정하고, 추정된 모델을 통해서 미래의 관측치 또는 통계량을 예측하게 된다.
> - 시계열 분석은 어떤 현상에 대해서 시간의 변화량을 기록한 시계열 자료를 대상으로 미래의 변화에 대한 추세를 분석하는 방법
> - ‘시간의 경과에 따른 관측값의 변화’를 패턴으로 인식하여 시계열 모형을 추정, 이 모형을 통해서 미래의 변화를 추정하는 분석 방법

- 특징
  - 회귀분석과 동일하게 설명변수와 반응변수를 토대로 유의수준에 의해서 판단하는 추론통계방식
  - y 변수 존재 : 시간 t를 설명변수(x)로 시계열Yt를 반응변수(y)로 사용한다.
  - 미래 예측 : 시간 축을 기준으로 계절성이 있는 데이터가 기록된 시계열 자료를 데이터 셋으로 이용한다.
  - 모수검정 : 선형성, 정규성, 등분산성 가정이 만족해야 한다.
  - 추론 기능 : 유의수준 판단 기준이 존재하는 추론통계 방식이다
  - 활용분야 : 경기계측, 판매예측, 주식시장분석, 예산 및 투자 분석 등에서 활용된다.



### 비정상 시계열

> 시간의 추이에 따라서 점진적으로 증가하는 추세와 분산이 일정하지 않은 경우 규칙성(비독립적)을 갖는 패턴으로 시간의 추이에 따라서 점진적으로 증가하거나 하강하는 추세(Trend)의 규칙, 일정한 주기(cycle) 단위로 동일한 규칙이 반복되는 계절성(Seasonality)의 규칙을 보인다.

- 비정상 시계열 자료를 정상성 시계열 자료 변환

  ```R
  data(AirPassengers)  #12년간 항공기 탑승 승객 수
  head(AirPassengers)
  str(AirPassengers)
  
  #차분을 이용한 평균에 대한 정상화
  par(mfrow=c(1,2))
  ts.plot(AirPassengers)   #시계열 시각화
  diff <- diff(AirPassengers)  #차분 수행
  plot(diff)   #평균 정상화
  
  
  #로그를 이용한 분산에 대한 정상화
  par(mfrow=c(1,2))
  plot(AirPassengers)
  log <-diff(log(AirPassengers))  #로그 + 차분 
  plot(log)
  ```

- 차분(Differencing) : 현재 시점에서 이전 시점의 자료를 빼는 연산으로 평균을 정상화하는데 이용

- 로그 변환 :  log() 함수를 이용하여 분산을 정상화하는 데 이용

### 정상 시계열

>어떤 시계열 자료의 변화 패턴이 일정한 평균값을 중심으로 일정한 변동 폭을 갖는 시계열일 때 (시간의 추이와 관계없이 평균과 분산이 일정) 평균이 0이며 일정한 분산을 갖는 정규분포에서 추출된 임의의 값으로 불규칙성(독립적)을 갖는 데이터 불규칙성을 갖는 패턴을 백색잡음(whitenoise)이라고 부른다.

```R
data(WWWusage)   #인터넷 사용시간을 분 단위로 측정 
str(WWWusage)    #측정치 : 100  , 자료구조 형태: 벡터

ts.plot(WWWusage, type="l", col="red")  #가로축 :t , 세로축:시계열 데이터 값

#다중 시계열 자료의 추세선 시각화
data(EuStockMarkets)  #유럽 주요 주식의 주가지수 일일 마감 가격  
str(EuStockMarkets)  #DAX:독일, SMI:스위스, CAC: 프랑스 , FISE:영국)
EuStock <- data.frame(EuStockMarkets);
X11()
plot(EuStock$DAX[1:1000], type="l", col="red")
plot(EuStock$DAX[1:1000],EuStock$SMI[1:1000], main="주가지수 추세선")
```



---



### 고급시각화

- 시각화 주요 패키지 : graphics, lattice, ggplot2, ggmap
- 이산변수 시각화 : barplot(), dotchart(), pie() 
- 연속변수 시각화 : boxplot(), hist(), plot()

- lattice 패키지는 서로 상관있는 확률적 종속변수의 시각화에 사용
- 특정 변수가 갖는 범주별로 독립된 패널을 격차(lattice)처럼 배치하여 
  여러 개의 변수에 대한 범주를 세부적으로 시각화해주는 도구를 제공

- ggplot2 패키지는 기하학적 객체들(점, 선, 막대 등)에 미적특성(색상, 모양, 크기)을 적용하여 시각화하는 방법을제공

- ggmap 패키지는 지도를 기반으로 위치, 영역, 시각과 공간에 따른 차이 및 변화를 다루는 공간시각화에 적합



- lattice 패키지

  ```R
  histogram()  
  densityplot() 연속형변수 밀도 그래프
  barchart() 
  dotplot()  점그래프
  xyplot()  교차그래프
  equal.count() 데이터셋에 지정된 영역만큼 범주화
  coplot() 조건 변수와 관련 조건 그래프 
  cloud()  3차원 산점도
  
  install.packages("lattice")
  library(lattice)
  
  install.packages("mlmRev")
  library(mlmRev)
  data(Chem97)
  #학생 대상 화확 점수를 기록한 데이터 셋
  
  str(Chem97)  # data.frame':  31022 obs. of  8 variables:
  #gcsescore : gcse개인평균성적
  #lea : 지방교육청
  table(Chem97$score)
  
  head(Chem97,30) # 앞쪽 30개 레코드 
  
  #  히스토그램 
  histogram( ~ gcsescore, data=Chem97) 
  # gcsescore변수를 대상으로 백분율 적용 히스토그램
  
  histogram # histogram(~x축 | 조건, dataframe)
  table(Chem97$score) #  0  2  4   6  8  10 <- 빈도수
  # score 변수를 조건으로 지정 
  histogram(~gcsescore | score, data=Chem97) # score 단위 
  histogram(~gcsescore | factor(score), data=Chem97) # score 요인 단위
  
  #  밀도 그래프 
  densityplot(~gcsescore | factor(score), data=Chem97, 
              groups = gender, plot.points=T, auto.key = T) 
  # 밀도 점 : plot.points=F
  # 범례: auto.key=T
  # 성별 단위(그룹화)로 GCSE점수를 밀도로 플로팅   
  ```

  

- 막대 그래프

  ```R
  # 1) 데이터셋 가져오기
  data(VADeaths)  #사망연령대, 도시출신, 남녀
  VADeaths
  str(VADeaths)
  
  # 2) 데이터셋 구조보기
  mode(VADeaths) # numeric
  class(VADeaths) # matrix
  
  # 3) 데이터 리모델링
  # (1) matrix -> data.frame 변환
  df <- as.data.frame(VADeaths)
  str(df) # 'data.frame':	5 obs. of  4 variables:
  class(df) # "data.frame"
  df 
  
  # (2) matrix -> data.table 변환
  dft <- as.data.frame.table(VADeaths)
  str(dft) # 'data.frame':  20 obs. of  3 variables:
  class(dft) # "data.frame"
  dft # Var1  Var2 Freq -> 1열 기준으로 data.table 생성
  
  # 막대 그래프 그리기  (x축은 사망비율, y축은 사망 연령대, 시골출신 , 도시출신)
  barchart(Var1 ~ Freq | Var2, data=dft, layout=c(4,1))
  # Var2변수 단위(그룹화)로 x축-Freq, y축-Var1으로 막대차트 플로팅
  
  # 막대 그래프 그리기(origin 속성 사용)
  barchart(Var1 ~ Freq | Var2, data=dft, layout=c(4,1), origin=0)
  ```

  

- 점 그래프

  ```R
  #dotplot(y축컬럼 ~x축 컬럼 | 조건, dataset , layout)
  dotplot(Var1 ~ Freq | Var2 , dft) 
  dotplot(Var1 ~ Freq | Var2 , dft, layout=c(4,1)) 
  
  #Var2변수 단위로 그룹화하여 점을 연결하여 플로팅  
  dotplot(Var1 ~ Freq, data=dft, groups=Var2, type="o", 
          auto.key=list(space="right", points=T, lines=T)) 
  ```

  

- 산점도 그래프

  ```R
  ######################### 산점도 그래프 ####################
  #xyplot(y축컬럼 ~x축 컬럼 | 조건변수, data=data.frame or list, layout)
  
  library(datasets)
  str(airquality) # datasets의 airqulity 테이터셋 로드
  
  airquality # Ozone Solar.R Wind Temp Month(5~9) Day
  
  # airquality의 Ozone(y),Wind(x) 산점도 플로팅
  xyplot(Ozone ~ Wind, data=airquality) 
  range(airquality$Ozone,na.rm=T)
  xyplot(Ozone ~ Wind | Month, data=airquality) # 2행3컬럼 
  xyplot(Ozone ~ Wind | factor(Month), data=airquality, layout=c(5,1))
  
  # airquality 데이터셋의 Month 타입변경(factor)
  convert <- transform(airquality, Month=factor(Month))
  str(convert) # Month 변수의 Factor값 확인
  # $ Month  : Factor w/ 5 levels "5","6","7","8"
  
  convert # Ozone Solar.R Wind Temp Month Day
  xyplot(Ozone ~ Wind | Month, data=convert, layout=c(5,1))
  # 컬럼 제목 : Month 값으로 출력
  
  
  #  quakes 데이터 셋으로 산점도 그래프 그리기 
  head(quakes)
  str(quakes) # 'data.frame':  1000 obs. of  5 variables:
  #lat(위도), long(경도), depth(수심), mag(리히터 규모), stations(관측소)
  range(quakes$stations)
  
  # 지진발생 위치(위도와 경로) 
  xyplot(lat~long, data=quakes, pch=".") 
  # 그래프를 변수에 저장
  tplot <- xyplot(lat~long, data=quakes, pch=".")
  # 그래프에 제목 추가
  tplot2<-update(tplot,
                 main="1964년 이후 태평양에서 발생한 지진위치")
  print(tplot2)
  
  
  ################# 산점도 그래프 그리기 ####################
  # 1. depth 이산형 변수 범위 확인 
  range(quakes$depth)# depth 범위
  
  # 2. depth 변수 리코딩 : 6개의 범주(100단위)로 코딩 변경
  quakes$depth2[quakes$depth >=40 & quakes$depth <=150] <- 1
  quakes$depth2[quakes$depth >=151 & quakes$depth <=250] <- 2
  quakes$depth2[quakes$depth >=251 & quakes$depth <=350] <- 3
  quakes$depth2[quakes$depth >=351 & quakes$depth <=450] <- 4
  quakes$depth2[quakes$depth >=451 & quakes$depth <=550] <- 5
  quakes$depth2[quakes$depth >=551 & quakes$depth <=680] <- 6
  
  # 3. 리코딩 변수(depth2)를 조건으로 산점도 그래프 그리기
  convert <- transform(quakes, depth2=factor(depth2))
  xyplot(lat~long | depth2, data=convert)
  
  
  # 동일한 패널에 2개의 y축에 값을 표현
  xyplot(Ozone + Solar.R ~ Wind | factor(Month), data=airquality,
         col=c("blue","red"),layout=c(5,1))
  ```

  ```R
  ################# equal.count() 함수 이용 이산형 변수 범주화 
  #################
  # equal.count(data, number=n, overlang=0)
  
  # (1) 1~150을 대상으로 겹치지 않게 4개 영역으로 범주화
  numgroup<- equal.count(1:150, number=4, overlap=0)
  numgroup
  
  # (2) 지진의 깊이를 5개 영역으로 범주화
  depthgroup<-equal.count(quakes$depth, number=5, overlap=0)
  depthgroup
  
  #범주화된 변수(depthgroup)를 조건으로 산점도 그래프 그리기 
  xyplot(lat ~ long | depthgroup, data=quakes,
         main="Fiji Earthquakes(depthgruop)",
         ylab="latitude", xlab="longitude", pch="@",col='red' )
  
  #수심과 리히터규모 변수를 동시에 적용하여 산점도 그래프 그리기 
  magnitudegroup<-equal.count(quakes$mag, number=2, overlap=0)
  magnitudegroup
  
  # magnitudegroup변수 기준으로 플로팅
  xyplot(lat ~ long | magnitudegroup, data=quakes,
         main="Fiji Earthquakes(magjitude)",
         ylab="latitude", xlab="longitude", pch="@", col='blue')
  
  
  # 수심과 리히터 규모를 동시에 표현(2행 5열 패널 구조)
  xyplot(lat ~ long | depthgroup*magnitudegroup, data=quakes,
         main="Fiji Earthquakes",
         ylab="latitude", xlab="longitude",
         pch="@",col=c("red","blue"))
  
  
  # 이산형 변수로 리코딩한 뒤에 factor 형으로 변환하여 산점도 그래프 그리기 
  quakes$depth3[quakes$depth >= 39.5 & quakes$depth <= 80.5] <- 'd1' 
  quakes$depth3[quakes$depth >= 79.5 & quakes$depth <= 186.5] <- 'd2' 
  quakes$depth3[quakes$depth >= 185.5 & quakes$depth <= 397.5] <- 'd3' 
  quakes$depth3[quakes$depth >= 396.5 & quakes$depth <= 562.5] <- 'd4' 
  quakes$depth3[quakes$depth >= 562.5 & quakes$depth <= 680.5] <- 'd5'
  
  quakes$mag3[quakes$mag >= 3.95 & quakes$mag <= 4.65] <- 'm1' 
  quakes$mag3[quakes$mag >= 4.55 & quakes$mag <= 6.45] <- 'm2'
  
  convert <- transform(quakes, depth3=factor(depth3), mag3=factor(mag3))
  
  xyplot(lat ~ long | depth3*mag3, data=convert, 
                      main="Fiji Earthquakes", ylab="latitude", 
                      xlab="longitude", pch="@", col=c("red", "blue"))
  ```

- 조건 그래프

  ```R
  coplot(lat~long | depth, data=quakes) # 2행3열, 0.5, 사이간격 6
  coplot(lat~long | depth, data=quakes, overlap=0.1) # 겹치는 구간 : 0.1
  coplot(lat~long | depth, data=quakes, number=5, row=1) # 사이간격 5, 1행 5열
  
  #  패널과 조건 막대에 색 적용 후 조건 그래프 그리기 
  coplot(lat~long | depth, data=quakes, number=5, row=1, panel=panel.smooth)
  coplot(lat~long | depth, data=quakes, number=5, row=1, 
         col='blue',bar.bg=c(num='green')) # 패널과 조건 막대 색 
  
  #   3차원 산점도 그래프 
  #   위도, 경도, 깊이를 이용하여 3차원 산점도 그래프 그리기 
  cloud(depth ~ lat * long , data=quakes,
        zlim=rev(range(quakes$depth)), 
        xlab="경도", ylab="위도", zlab="깊이")
  
  #   테두리와 회전 속성을 추가하여 3차원 산점도 그래프 그리기 
  cloud(depth ~ lat * long , data=quakes,
        zlim=rev(range(quakes$depth)), 
        panel.aspect=0.9,
        screen=list(z=45,x=-25),
        xlab="경도", ylab="위도", zlab="깊이")
  ```

  

### 지도 공간 기법 시각화 

> Google Static Maps API 이용

```R
geocode() : 거리주소 또는 장소 이름을 이용하여 지도 정보(위도, 경도) 얻을 수 있음 
get_googlemap() : 구글 지도서비스 API에 접근하여 정적 지도 다운로드 지원과 지도에 마커(maker)등을 삽입하고 자신이 원하는 줌 레벨과 중심점을 지정하여 지도 정보 생성
get_map() : 지도 서비스 관련 서버(GoogleMaps, OpenStreetMap, StamenMapsor, Naver Map)에 관련된 질의어를 지능형으로 인식하여 지도 정보 생성
get_navermap() : 네이버 지도서비스 API에 접근하여 정적 지도 다운로드 지원
ggimage() : ggplot2 패키지의 이미지와 동등한 수준으로 지도 이미지 생성
ggmap() 과 ggmapplot() : get_map()에 의해서 생성된 픽셀 객체를 지도 이미지로 시각화
qmap() : ggmap()과 get_map() 통합 기능
qmplot() : ggplot2 패키지의 qplot()과 동등한 수준으로 빠르게 지도 이미지 시각화
```

```R
#get_googlemap(center, zoom, size, scale, format, maptype, language, sensor, color, markers, path)
#get_map(location, zoom, scale, maptype, source, color, language, api_key)


########### 4.1 Google Static Maps API 이용 
remove.packages("ggmap")
remove.packages("tibble")
#install.packages('devtools')
library('devtools')
install_github('dkahle/ggmap', ref="tidyup")
library('ggmap')

#구글에 로그인하여 https://cloud.google.com/maps-platform/#get-started 에 접속 

register_google(key='발급받은키') # 부여받은 키 등록
names <- c("용두암","성산일출봉","정방폭포",
            "중문관광단지","한라산1100고지","차귀도")
addr <- c("제주시 용두암길 15",
           "서귀포시 성산읍 성산리",
           "서귀포시 동홍동 299-3",
           "서귀포시 중문동 2624-1",
           "서귀포시 색달동 산1-2",
           "제주시 한경면 고산리 125")
gc <- geocode(enc2utf8(addr))
 
# 지도위치정보 가져오기
gc <- geocode("seoul")
center <- as.numeric(gc)
center # 위도,경도

# 지도 정보 생성하기
map <- get_googlemap(center = center, language="ko-KR", color = "bw", scale = 2 )

# 지도 이미지 그리기
ggmap(map, extent = 'device')

# 지도 위에 marker 삽입하기 
df <- round(data.frame(x=jitter(rep(-95.36, 25), amount=.3), 
              y=jitter(rep(29.76, 25), amount=.3) ), digits=2)

map <- get_googlemap('houston', markers=df, path=df, scale=2)

ggmap(map, extent = 'device')

###############종합지도 서비스 관련 API 이용  

# roadmap 타입으로 지도 그리기
map <- get_map(location ="london", zoom=14, maptype='roadmap', scale=2)
# get_map("중심지역", 확대비율, 지도유형) : ggmap에서 제공하는 함수 
ggmap(map, size=c(600,600), extent='device')

# watercolor 타입으로 지도 그리기
map <- get_map(location ="seoul", zoom=8, maptype='watercolor', scale=2)
ggmap(map, size=c(600,600), extent='device')


######## 지도 이미지에 레이어 적용  

# 서울지역 4년제 대학교 위치 표시 
university <- read.csv("./data/university.csv",header=T)
university # # 학교명","LAT","LON"

# 레이어1 : 정적 지도 생성 
kor <- get_map('seoul', zoom = 11, maptype = 'watercolor')
ggmap(kor)

# 레이어2 : 지도위에 포인트 추가 
ggmap(kor)+geom_point(data=university, aes(x=LON, y=LAT,color=factor(학교명)),size=3)
kor.map <- ggmap(kor)+geom_point(data=university, aes(x=LON, y=LAT,color=factor(학교명)),size=3)

# 레이어3 : 지도위에 텍스트 추가
kor.map + geom_text(data=university, aes(x=LON+0.01, y=LAT+0.01,label=학교명),size=5)


# 지도 저장하기
ggsave("./otuput/university1.png",width=10.24,height=7.68)
# 밀도 적용 파일 저장
ggsave("./otuput/university2.png",dpi=1000) # 9.21 x 7.68 in image
```

